import streamlit as st
import google.generativeai as genai
from PIL import Image
import pypdf
import io

# --- SAYFA AYARLARI ---
st.set_page_config(
    page_title="VatandaÅŸ Dili Ã‡evirmeni",
    page_icon="âš–ï¸",
    layout="wide"
)

# --- CSS Ä°LE GÃœZELLEÅTÄ°RME (Ä°steÄŸe BaÄŸlÄ±) ---
st.markdown("""
<style>
    .stChatMessage {border-radius: 10px; padding: 10px;}
    .stButton button {border-radius: 20px;}
</style>
""", unsafe_allow_html=True)

# --- HAFIZA BAÅLATMA ---
if "analyzed_text" not in st.session_state:
    st.session_state.analyzed_text = ""
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "summary_report" not in st.session_state:
    st.session_state.summary_report = ""

# --- GÄ°ZLÄ° ANAHTAR ---
try:
    if "GOOGLE_API_KEY" in st.secrets:
        api_key = st.secrets["GOOGLE_API_KEY"]
    else:
        st.error("API AnahtarÄ± bulunamadÄ±.")
        st.stop()
except:
    st.stop()

# --- YAN MENÃœ ---
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/9252/9252103.png", width=80)
    st.title("Hukuk AsistanÄ±")
    
    # Temizle Butonu
    if st.button("ğŸ—‘ï¸ Yeni Belge / Temizle", use_container_width=True):
        st.session_state.analyzed_text = ""
        st.session_state.chat_history = []
        st.session_state.summary_report = ""
        st.rerun()
    
    st.divider()
    
    with st.expander("âš™ï¸ Model AyarlarÄ±"):
        try:
            genai.configure(api_key=api_key)
            model_list = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods and '1.5' in m.name and 'exp' not in m.name]
            if not model_list: model_list = ['gemini-1.5-flash']
            selected_model = st.selectbox("Yapay Zeka:", model_list)
        except:
            st.error("BaÄŸlantÄ± sorunu.")
            
    st.info("ğŸ’¡ **Ä°pucu:** Kira sÃ¶zleÅŸmesi, banka kredisi veya ihtarname yÃ¼kleyebilirsiniz.")

# --- FONKSÄ°YONLAR ---
def get_gemini_response(prompt_text):
    model = genai.GenerativeModel(selected_model)
    full_prompt = f"""
    Sen bir hukuk asistanÄ±sÄ±n. AÅŸaÄŸÄ±daki BELGE METNÄ°NE dayanarak cevap ver.
    
    BELGE METNÄ°: {st.session_state.analyzed_text[:15000]}
    
    SORU/Ä°STEK: {prompt_text}
    """
    return model.generate_content(full_prompt).text

# --- ANA EKRAN ---
st.title("ğŸ“„ Belgenle Sohbet Et")

# 1. YÃœKLEME EKRANI
if not st.session_state.analyzed_text:
    st.markdown("Belgeni yÃ¼kle, **gizli riskleri bulalÄ±m** ve **aklÄ±n takÄ±lanlarÄ± cevaplayalÄ±m.**")
    
    tab1, tab2 = st.tabs(["ğŸ“„ Metin YapÄ±ÅŸtÄ±r", "ğŸ“‚ PDF/Foto YÃ¼kle"])
    raw_text = ""
    
    with tab1:
        text_input = st.text_area("Metni buraya yapÄ±ÅŸtÄ±r:", height=200)
        if st.button("Metni Analiz Et", type="primary"):
            raw_text = text_input

    with tab2:
        uploaded_file = st.file_uploader("Dosya seÃ§ (PDF, JPG, PNG)", type=["pdf", "jpg", "png", "jpeg"])
        if uploaded_file and st.button("DosyayÄ± Analiz Et", type="primary"):
            with st.spinner("Belge taranÄ±yor..."):
                if "pdf" in uploaded_file.type:
                    try:
                        reader = pypdf.PdfReader(uploaded_file)
                        for page in reader.pages:
                            raw_text += page.extract_text() + "\n"
                    except: st.error("PDF okunamadÄ±.")
                else:
                    try:
                        img = Image.open(uploaded_file)
                        model = genai.GenerativeModel(selected_model)
                        response = model.generate_content(["Bu gÃ¶rseldeki metni formatÄ±nÄ± koruyarak Ã§Ä±kar:", img])
                        raw_text = response.text
                    except: st.error("GÃ¶rsel okunamadÄ±.")

    if raw_text:
        st.session_state.analyzed_text = raw_text
        st.rerun()

# 2. ANALÄ°Z VE SOHBET EKRANI
else:
    # Otomatik Ã–zet (Sadece ilk seferde)
    if not st.session_state.chat_history:
        with st.spinner("Yapay zeka avukatÄ±nÄ±z belgeyi inceliyor..."):
            try:
                summary_prompt = """
                Bu hukuki metni analiz et. Ã‡Ä±ktÄ± formatÄ±:
                ## ğŸ“Š Belge Ã–zeti
                **Konu:** ...
                **Riskler:** (Madde madde, varsa âš ï¸ ikonu ile)
                **Tavsiye:** ...
                """
                summary = get_gemini_response(summary_prompt)
                st.session_state.summary_report = summary # Ä°ndirmek iÃ§in sakla
                st.session_state.chat_history.append({"role": "assistant", "content": summary})
            except Exception as e:
                st.error(f"Analiz hatasÄ±: {e}")

    # Rapor Ä°ndirme Butonu (SaÄŸ Ã¼st kÃ¶ÅŸe gibi)
    col1, col2 = st.columns([3, 1])
    with col2:
        st.download_button(
            label="ğŸ“¥ Analizi Ä°ndir (TXT)",
            data=st.session_state.summary_report,
            file_name="hukuk_analizi.txt",
            mime="text/plain"
        )

    # Sohbet GeÃ§miÅŸini GÃ¶ster
    for message in st.session_state.chat_history:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # HIZLI SORU BUTONLARI
    st.write("")
    st.markdown("##### âš¡ HÄ±zlÄ± Sorular:")
    b1, b2, b3, b4 = st.columns(4)
    
    prompt_trigger = None
    
    if b1.button("Para/Ceza Var mÄ±? ğŸ’°"): prompt_trigger = "Bu belgede para cezasÄ±, tazminat veya ekstra Ã¶deme gerektiren maddeler var mÄ±?"
    if b2.button("Ne Zaman Biter? ğŸ“…"): prompt_trigger = "SÃ¶zleÅŸme sÃ¼resi ne kadar, fesih tarihleri ve koÅŸullarÄ± neler?"
    if b3.button("Riskli Madde? âš ï¸"): prompt_trigger = "Ä°mzalamadan Ã¶nce dikkat etmem gereken en tehlikeli madde hangisi?"
    if b4.button("HakkÄ±m Nedir? âš–ï¸"): prompt_trigger = "Bu belgeye gÃ¶re yasal haklarÄ±m ve avantajlarÄ±m neler?"

    # Chat GiriÅŸi
    user_input = st.chat_input("Veya kendi sorunu yaz...")

    # Ä°ÅŸlem MantÄ±ÄŸÄ± (Buton veya YazÄ±)
    prompt = prompt_trigger if prompt_trigger else user_input

    if prompt:
        # KullanÄ±cÄ± mesajÄ±nÄ± ekle
        st.session_state.chat_history.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # Cevap Ãœret
        with st.chat_message("assistant"):
            with st.spinner("Cevap yazÄ±lÄ±yor..."):
                response_text = get_gemini_response(prompt)
                st.markdown(response_text)
                st.session_state.chat_history.append({"role": "assistant", "content": response_text})
